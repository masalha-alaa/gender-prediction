{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masalha-alaa/gender-prediction/blob/master/gender_recognition_bert_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb -q\n",
        "!pip install transformers datasets -q\n",
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2_ErDN66DZL",
        "outputId": "e3a62495-756e-443e-8ca8-fd1593d30978"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJLJi95l9Pjp",
        "outputId": "913c6e0b-3fde-4e7a-becf-927c6c6a062e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from json import load as j_load, loads as j_loads\n",
        "from collections import defaultdict\n",
        "from multiprocessing import cpu_count, Pool\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import emoji\n",
        "\n",
        "import torch\n",
        "from datasets import DatasetDict, load_dataset\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk import word_tokenize\n",
        "from nltk import data as nltk_data, pos_tag\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "import import_ipynb\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "NGRAM_LEN = (1)\n",
        "MOST_COMMON = 1150"
      ],
      "metadata": {
        "id": "v48_I8-s9MRf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUu-7gfL-lNj",
        "outputId": "64acaaec-52cd-483a-c88a-171c9cacad9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BpcJL8slBDKG"
      },
      "outputs": [],
      "source": [
        "# Dataframe columns\n",
        "TEXT = 'txt'\n",
        "URL = 'url'\n",
        "AUTHOR = 'author'\n",
        "LABEL = GENDER = 'gender'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IrrS03-ZBxSQ"
      },
      "outputs": [],
      "source": [
        "def get_emoji_regexp():\n",
        "    # https://github.com/carpedm20/emoji/issues/222#issuecomment-1200303280\n",
        "    # Sort emoji by length to make sure multi-character emojis are\n",
        "    # matched first\n",
        "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
        "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
        "    return re.compile(pattern)\n",
        "\n",
        "\n",
        "def clean_line_parallel(params):\n",
        "    part, emoticons_ = params\n",
        "    return part.apply(lambda row: clean_line(row, emoticons_))\n",
        "\n",
        "\n",
        "def clean_line(line, emos=None):\n",
        "    if not line:\n",
        "        return ''\n",
        "    EMOJI = r'emj'\n",
        "    URL = r'url'\n",
        "    PUNCT = r'pnc'\n",
        "    remove = ['your comment has been removed', 'this comment or post has been removed', 'removed ', 'removed. ',\n",
        "              'your submission has been remove', 'this post has been removed', 'your post has been removed']\n",
        "    line = line.lower()\n",
        "    if any(re.match(r, line) for r in remove):\n",
        "        return ''\n",
        "    line = get_emoji_regexp().sub(EMOJI, line)\n",
        "    if emos is None:\n",
        "        emoticons_ = emoticons\n",
        "    else:\n",
        "        emoticons_ = emos\n",
        "    for emoticon in emoticons_:\n",
        "        line = line.replace(emoticon, EMOJI)\n",
        "    line = re.sub(r'\\(?http\\S+\\)?', URL, line)\n",
        "    return line\n",
        "\n",
        "\n",
        "def posify(txt):\n",
        "    \"\"\"\n",
        "    Converts txt to part of speech tags\n",
        "    \"\"\"\n",
        "    return ' '.join([pair[1] for pair in pos_tag(txt.split())])\n",
        "\n",
        "\n",
        "def posifyNew(txt):\n",
        "    \"\"\"\n",
        "    Converts txt to pairs of word & POS\n",
        "    \"\"\"\n",
        "    return ' '.join([' '.join(pos) for pos in pos_tag(txt.split())])\n",
        "\n",
        "\n",
        "def posifyNew2(txt):\n",
        "    \"\"\"\n",
        "    Appends pos text to txt\n",
        "    \"\"\"\n",
        "    return txt + ' ' + ' '.join([pos[1] for pos in pos_tag(txt.split())])\n",
        "\n",
        "\n",
        "def sentecize(txt):\n",
        "    return tokenizer.tokenize(txt)\n",
        "\n",
        "\n",
        "def aggregate(df, sentences_n=4):\n",
        "    df_agg = df.groupby(df.index // sentences_n).agg({'txt': ' '.join, 'pos': ' '.join, 'txt_with_sentiments': ' '.join, 'gender': 'first'}).reset_index(drop=True).copy()\n",
        "    return df_agg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMOJI = r'emj'\n",
        "URL = r'url'\n",
        "MALE, FEMALE = 0, 1\n",
        "lbl_to_id = {\"male\": MALE, \"female\": FEMALE}\n",
        "id_to_lbl = {i: lbl for lbl,i in lbl_to_id.items()}"
      ],
      "metadata": {
        "id": "_jRZcgFbL2ni"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETcKorg5Bo2W",
        "outputId": "3d5beb5b-5214-4be5-d7bc-3cb0a6778b66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun 26 Mar 2023 02:08:24 PM UTC\n",
            "Program started\n",
            "Sun 26 Mar 2023 02:08:24 PM UTC\n"
          ]
        }
      ],
      "source": [
        "!date\n",
        "\n",
        "ts = datetime.now()\n",
        "print('Program started')\n",
        "\n",
        "PRECUT = 0.30\n",
        "CLASS_SIZE = None  # None to take min max\n",
        "SELECT_K_BEST = 100\n",
        "TRAIN_FRAC = 0.70\n",
        "MIN_SENT_LEN = 5  # in tokens  # TODO: Do some trials\n",
        "\n",
        "DRIVE_ROOT_DATA_DIR = Path(\"/content/gdrive/MyDrive/gender-project/\")\n",
        "DATASET_PATH = DRIVE_ROOT_DATA_DIR / \"dataset3 and 2021-11-06 19-51-29\"\n",
        "RAW_DATASET_PATH = DATASET_PATH / \"raw\"\n",
        "CLEAN_DATASET_PATH = DATASET_PATH / \"clean\"\n",
        "EXTRA_DIR = DRIVE_ROOT_DATA_DIR / \"extra\"\n",
        "EMOTICONS_LST_FILE = \"emoticons.txt\"\n",
        "FUNCTION_WORDS_LST_FILE = \"fw.txt\"\n",
        "\n",
        "# read dataset\n",
        "if not os.path.exists(CLEAN_DATASET_PATH / \"train.parquet\"):\n",
        "    data = pd.read_csv(RAW_DATASET_PATH / \"data.csv\")\n",
        "    if 0 < PRECUT < 1:\n",
        "        data = data.sample(frac=PRECUT, random_state=SEED)\n",
        "\n",
        "    data = data.drop(data[(data.gender != 'male') & (data.gender != 'female')].index).reset_index(drop=True)\n",
        "\n",
        "    # Clean\n",
        "    clean_ts = datetime.now()\n",
        "    print('Cleaning...', end=' ')\n",
        "    with open(EXTRA_DIR / EMOTICONS_LST_FILE) as f:\n",
        "        emoticons = [emoticon.lower() for emoticon in list(set(f.read().split()))]\n",
        "    if MIN_SENT_LEN > 1:\n",
        "        # TODO: Ditch short before or after exploding?!\n",
        "        data[data.txt.str.split().apply(len) < MIN_SENT_LEN] = ''\n",
        "        # data = data[data.txt.str.split().apply(len) >= MIN_SENT_LEN].reset_index(drop=True)\n",
        "\n",
        "    # PARALLEL BEGIN\n",
        "    pools = cpu_count()\n",
        "    with Pool(pools) as pool:\n",
        "        groups = [(part, emoticons) for part in np.array_split(data['txt'], pools)]\n",
        "        data['txt'] = pd.concat(pool.map(clean_line_parallel, groups), axis=0)\n",
        "    # PARALLEL END\n",
        "\n",
        "    data = data.replace('', np.nan).dropna().reset_index(drop=True)\n",
        "    print(datetime.now() - clean_ts)\n",
        "\n",
        "    # split to genders\n",
        "    print('Splitting to genders...')\n",
        "    male = data.loc[data['gender'] == 'male', ['txt']]\n",
        "    female = data.loc[data['gender'] == 'female', ['txt']]\n",
        "\n",
        "    # split to sentences\n",
        "    print('Splitting to sentences...')\n",
        "    tokenizer = nltk_data.load('tokenizers/punkt/english.pickle')\n",
        "    male = male.apply(lambda row: sentecize(row['txt']), axis=1).explode('txt').apply(lambda row: row.strip()).replace('', np.nan).dropna().to_frame('txt').copy().reset_index(drop=True)\n",
        "    female = female.apply(lambda row: sentecize(row['txt']), axis=1).explode('txt').apply(lambda row: row.strip()).replace('', np.nan).dropna().to_frame('txt').copy().reset_index(drop=True)\n",
        "\n",
        "    # sentiment analysis per sentence\n",
        "    def createSentiments(ser, sia):\n",
        "        sentiments = ser.apply(lambda row: {k:v for k,v in sia.polarity_scores(row).items() if k != 'compound'})\n",
        "        return sentiments\n",
        "\n",
        "    print('Sentiment analysis...', end=' ')\n",
        "    sia_ts = datetime.now()\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiments = createSentiments(male['txt'], sia)\n",
        "    male['txt_with_sentiments'] = male.apply(lambda row: row['txt'] + ' ' + max(sentiments[row.name], key=sentiments[row.name].get), axis=1)\n",
        "    sentiments = createSentiments(female['txt'], sia)\n",
        "    female['txt_with_sentiments'] = female.apply(lambda row: row['txt'] + ' ' + max(sentiments[row.name], key=sentiments[row.name].get), axis=1)\n",
        "    print(datetime.now() - sia_ts)\n",
        "    print(f\"Example: {male['txt_with_sentiments'][0]}\")\n",
        "\n",
        "    # posify\n",
        "    print('Posifying...', end=' ')\n",
        "    ts_pos = datetime.now()\n",
        "    with Pool(cpu_count()) as pool:\n",
        "        # only pos\n",
        "        # male['pos'] = pool.map(posify, male['txt'])\n",
        "        # female['pos'] = pool.map(posify, female['txt'])\n",
        "        # txt and pos together\n",
        "        male['pos'] = pool.map(posifyNew, male['txt'])\n",
        "        female['pos'] = pool.map(posifyNew, female['txt'])\n",
        "    print(datetime.now() - ts_pos)\n",
        "\n",
        "    # add labels\n",
        "    print('Adding labels...')\n",
        "    male['gender'] = [id_to_lbl[MALE]] * len(male)\n",
        "    female['gender'] = [id_to_lbl[FEMALE]] * len(female)\n",
        "\n",
        "    # sample randomly and aggregate\n",
        "    select_n = CLASS_SIZE if CLASS_SIZE and CLASS_SIZE <= min(len(male), len(female)) else min(len(male), len(female))\n",
        "    print(f'Class size: {select_n}')\n",
        "    print('Shuffling and aggregating...')\n",
        "    male = male.sample(n=select_n, random_state=SEED).reset_index(drop=True)\n",
        "    female = female.sample(n=select_n, random_state=SEED).reset_index(drop=True)\n",
        "    male = aggregate(male)\n",
        "    female = aggregate(female)\n",
        "    print(f'Class size (M,F): {len(male)}, {len(female)}')\n",
        "\n",
        "    # merge and shuffle\n",
        "    print('Merging and shuffling...')\n",
        "    data = pd.concat([male, female]).reset_index(drop=True).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "    # split to train / test\n",
        "    print('Splitting to train / test...')\n",
        "    test = data.iloc[int(len(data) * TRAIN_FRAC):].reset_index(drop=True)\n",
        "    train = data.iloc[:int(len(data) * TRAIN_FRAC)]\n",
        "    print(f'Train size: {len(train)}')\n",
        "    print(f'Test size: {len(test)}')\n",
        "    display(pd.concat((train[LABEL].value_counts().rename(\"train\"), test[LABEL].value_counts().rename(\"test\")), axis=1))\n",
        "\n",
        "    if not os.path.exists(CLEAN_DATASET_PATH):\n",
        "        os.makedirs(CLEAN_DATASET_PATH)\n",
        "\n",
        "    train.to_json(CLEAN_DATASET_PATH / \"train.json\")\n",
        "    train.to_parquet(CLEAN_DATASET_PATH / \"train.parquet\")\n",
        "\n",
        "    test.to_json(CLEAN_DATASET_PATH / \"validation.json\")\n",
        "    test.to_parquet(CLEAN_DATASET_PATH / \"validation.parquet\")\n",
        "\n",
        "!date"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    del train\n",
        "    del test\n",
        "except NameError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "0soDNu3nKyR3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.read_parquet(CLEAN_DATASET_PATH / \"train.parquet\")\n",
        "columns = temp.columns.tolist()\n",
        "display(temp.head(1))\n",
        "del temp\n",
        "dataset = load_dataset(\"parquet\",\n",
        "                    data_files={\"train\": str(CLEAN_DATASET_PATH / \"train.parquet\"),\n",
        "                                \"validation\": str(CLEAN_DATASET_PATH / \"validation.parquet\")})\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332,
          "referenced_widgets": [
            "7de452ca7835461dab904ba15bd7093c",
            "edbca7b770bb409da93aeb25b10cf594",
            "8c261742176b4123954a5fbd67927a27",
            "c8f79ab28ff04cbbb1f13ee687434c58",
            "bddd0866630545cf8aa11a96aacc495e",
            "aff08d0122a34c38901950c8148ad0b0",
            "202d66db58764df2b9362f9c44d62b4c",
            "cafb91c82aa244e79a83d2e64fda2bbb",
            "37bd98ce7a8a44bdae91645beb140180",
            "9a2d656bb289419ab95142925fb112c0",
            "1a14445c30be4e669c8ed741d699e8b6"
          ]
        },
        "id": "AqDc3hNqK4ql",
        "outputId": "d588aabd-20ba-41f7-e412-d9ec63c057a4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 txt  \\\n",
              "0  people really don't understand this. the only ...   \n",
              "\n",
              "                                                 pos gender  \n",
              "0  people NNS really RB don't JJ understand NN th...   male  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef2de089-6b16-4056-8972-5cc3fe967eeb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>pos</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>people really don't understand this. the only ...</td>\n",
              "      <td>people NNS really RB don't JJ understand NN th...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef2de089-6b16-4056-8972-5cc3fe967eeb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef2de089-6b16-4056-8972-5cc3fe967eeb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef2de089-6b16-4056-8972-5cc3fe967eeb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/default-eda354a4b2128ccf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7de452ca7835461dab904ba15bd7093c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['txt', 'pos', 'gender', '__index_level_0__'],\n",
              "        num_rows: 15910\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['txt', 'pos', 'gender', '__index_level_0__'],\n",
              "        num_rows: 6820\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(pd.Series(dataset[\"train\"][LABEL]).rename(\"train\").value_counts(dropna=False))\n",
        "print(\"\")\n",
        "display(pd.Series(dataset[\"validation\"][LABEL]).rename(\"test\").value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "5JW-Ln8fLgvT",
        "outputId": "af18554a-4c1d-4172-818a-859a4b6c91a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "male      7970\n",
              "female    7940\n",
              "Name: train, dtype: int64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "female    3425\n",
              "male      3395\n",
              "Name: test, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import cpu_count\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 4\n",
        "model_path = \"bert-base-uncased\"\n",
        "# model_path = \"Fan-s/reddit-tc-bert\"\n",
        "num_labels = len(lbl_to_id)\n",
        "num_workers = cpu_count()\n",
        "print(f\"{num_workers = }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdotBsv_L7Ny",
        "outputId": "5f371dcf-190e-4ecb-f46a-fd815f393f93"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_workers = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Running on {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "804LoMEcMDmX",
        "outputId": "181d1316-bcf5-466c-9aa6-44a1d8bd3bdb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    encoded = tokenizer(examples[TEXT],\n",
        "                        padding=\"max_length\",\n",
        "                        truncation=True,\n",
        "                        return_tensors=\"pt\")\n",
        "    encoded[\"labels\"] = [lbl_to_id[ex] for ex in examples[LABEL]]\n",
        "    return encoded\n",
        "\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize_function, batched=True, num_proc=num_workers, remove_columns=columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqiHNHASM3wH",
        "outputId": "21c4b43f-0cc3-48c1-f588-8542eacead00"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/parquet/default-eda354a4b2128ccf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-044d7a01ce532171_*_of_00002.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/parquet/default-eda354a4b2128ccf/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-8771307f3b98866c_*_of_00002.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
        "                                                           label2id=lbl_to_id,\n",
        "                                                           id2label=id_to_lbl,\n",
        "                                                           num_labels=num_labels).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ4KqLnKNmfw",
        "outputId": "1059f0b6-bc69-4cfb-9b20-30e55772f07c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "gradient_accumulation_steps = 4\n",
        "iters_per_epoch = len(dataset[\"train\"][LABEL]) // (BATCH_SIZE * gradient_accumulation_steps)\n",
        "training_args = TrainingArguments(evaluation_strategy='epoch',\n",
        "                                  optim='adamw_torch',\n",
        "                                  logging_steps=iters_per_epoch,\n",
        "                                  per_device_train_batch_size=BATCH_SIZE,\n",
        "                                  per_device_eval_batch_size=BATCH_SIZE,\n",
        "                                  num_train_epochs=EPOCHS,\n",
        "                                  save_total_limit=1,\n",
        "                                  save_strategy='epoch',\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  fp16=device == 'cuda',\n",
        "                                  gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "                                  output_dir='model_checkpoints')"
      ],
      "metadata": {
        "id": "Q5YBEJCPNtnG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    preds = np.argmax(preds, axis=-1)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=0)\n",
        "    p_per_lbl, r_per_lbl, f1_per_lbl, _ = precision_recall_fscore_support(\n",
        "        y_true=labels, y_pred=preds, labels=range(num_labels), average=None, zero_division=0\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    d = {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1}\n",
        "\n",
        "    for id_ in range(num_labels):\n",
        "        cls = id_to_lbl[id_]\n",
        "        d[f\"{cls} precision\"] = p_per_lbl[id_]\n",
        "        d[f\"{cls} recall\"] = r_per_lbl[id_]\n",
        "        d[f\"{cls} f1\"] = f1_per_lbl[id_]\n",
        "\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "4btvW5wBOA3f"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "v-B4h1JoOJMV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "MP90Jw8DOLmB",
        "outputId": "95b59371-8233-4bca-cb27-a8a7449d3800"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [992/992 40:41, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Male precision</th>\n",
              "      <th>Male recall</th>\n",
              "      <th>Male f1</th>\n",
              "      <th>Female precision</th>\n",
              "      <th>Female recall</th>\n",
              "      <th>Female f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.574200</td>\n",
              "      <td>0.513008</td>\n",
              "      <td>0.748827</td>\n",
              "      <td>0.763811</td>\n",
              "      <td>0.748827</td>\n",
              "      <td>0.745013</td>\n",
              "      <td>0.826475</td>\n",
              "      <td>0.627099</td>\n",
              "      <td>0.713113</td>\n",
              "      <td>0.701697</td>\n",
              "      <td>0.869489</td>\n",
              "      <td>0.776633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.353900</td>\n",
              "      <td>0.540351</td>\n",
              "      <td>0.763783</td>\n",
              "      <td>0.766330</td>\n",
              "      <td>0.763783</td>\n",
              "      <td>0.763289</td>\n",
              "      <td>0.739656</td>\n",
              "      <td>0.810898</td>\n",
              "      <td>0.773641</td>\n",
              "      <td>0.792770</td>\n",
              "      <td>0.717080</td>\n",
              "      <td>0.753028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.152100</td>\n",
              "      <td>0.686298</td>\n",
              "      <td>0.769941</td>\n",
              "      <td>0.771455</td>\n",
              "      <td>0.769941</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.791321</td>\n",
              "      <td>0.730486</td>\n",
              "      <td>0.759688</td>\n",
              "      <td>0.751763</td>\n",
              "      <td>0.809051</td>\n",
              "      <td>0.779356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.056200</td>\n",
              "      <td>1.052959</td>\n",
              "      <td>0.763490</td>\n",
              "      <td>0.770444</td>\n",
              "      <td>0.763490</td>\n",
              "      <td>0.761838</td>\n",
              "      <td>0.813512</td>\n",
              "      <td>0.681001</td>\n",
              "      <td>0.741382</td>\n",
              "      <td>0.727753</td>\n",
              "      <td>0.845255</td>\n",
              "      <td>0.782115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = DRIVE_ROOT_DATA_DIR / \"pytorch_bert\"\n",
        "best_model_zipped_path = f\"{best_model_path}.zip\"\n",
        "if os.path.exists(best_model_path):\n",
        "    !rm -r {best_model_path}\n",
        "if os.path.exists(best_model_zipped_path):\n",
        "    !rm {best_model_zipped_path}\n",
        "\n",
        "trainer.save_model(best_model_path)\n",
        "!zip -j -r {best_model_zipped_path} {best_model_path}\n",
        "!rm -r {best_model_path}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uRuCYmvQFwD",
        "outputId": "adf691d7-8ff0-43ea-c5cc-152cb6bcec4c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: config.json (deflated 50%)\n",
            "  adding: pytorch_model.bin (deflated 7%)\n",
            "  adding: training_args.bin (deflated 49%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7de452ca7835461dab904ba15bd7093c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edbca7b770bb409da93aeb25b10cf594",
              "IPY_MODEL_8c261742176b4123954a5fbd67927a27",
              "IPY_MODEL_c8f79ab28ff04cbbb1f13ee687434c58"
            ],
            "layout": "IPY_MODEL_bddd0866630545cf8aa11a96aacc495e"
          }
        },
        "edbca7b770bb409da93aeb25b10cf594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aff08d0122a34c38901950c8148ad0b0",
            "placeholder": "",
            "style": "IPY_MODEL_202d66db58764df2b9362f9c44d62b4c",
            "value": "100%"
          }
        },
        "8c261742176b4123954a5fbd67927a27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cafb91c82aa244e79a83d2e64fda2bbb",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37bd98ce7a8a44bdae91645beb140180",
            "value": 2
          }
        },
        "c8f79ab28ff04cbbb1f13ee687434c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a2d656bb289419ab95142925fb112c0",
            "placeholder": "",
            "style": "IPY_MODEL_1a14445c30be4e669c8ed741d699e8b6",
            "value": " 2/2 [00:00&lt;00:00, 83.36it/s]"
          }
        },
        "bddd0866630545cf8aa11a96aacc495e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aff08d0122a34c38901950c8148ad0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202d66db58764df2b9362f9c44d62b4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cafb91c82aa244e79a83d2e64fda2bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37bd98ce7a8a44bdae91645beb140180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a2d656bb289419ab95142925fb112c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a14445c30be4e669c8ed741d699e8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}