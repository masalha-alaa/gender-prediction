{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masalha-alaa/gender-prediction/blob/master/gender_recognition_with_sentiment_bert_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install import-ipynb -q\n",
        "!pip install transformers datasets -q\n",
        "!pip install emoji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2_ErDN66DZL",
        "outputId": "8d7c9e9c-97a6-4bfb-93d3-165d625222e5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.9/dist-packages (2.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJLJi95l9Pjp",
        "outputId": "d283b8a6-9577-4d34-8f97-b99ae7fd43df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import re\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "from json import load as j_load, loads as j_loads\n",
        "from collections import defaultdict\n",
        "from multiprocessing import cpu_count, Pool\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import emoji\n",
        "\n",
        "import torch\n",
        "from datasets import DatasetDict, load_dataset\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk import word_tokenize\n",
        "from nltk import data as nltk_data, pos_tag\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "import import_ipynb\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "NGRAM_LEN = (1)\n",
        "SENTENCES_N = 4\n",
        "MOST_COMMON = 1150"
      ],
      "metadata": {
        "id": "v48_I8-s9MRf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUu-7gfL-lNj",
        "outputId": "fdbfcf3b-80d9-4ce6-ad94-c6ebda249e27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BpcJL8slBDKG"
      },
      "outputs": [],
      "source": [
        "# Dataframe columns\n",
        "TEXT = 'txt'\n",
        "URL = 'url'\n",
        "AUTHOR = 'author'\n",
        "LABEL = GENDER = 'gender'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IrrS03-ZBxSQ"
      },
      "outputs": [],
      "source": [
        "def get_emoji_regexp():\n",
        "    # https://github.com/carpedm20/emoji/issues/222#issuecomment-1200303280\n",
        "    # Sort emoji by length to make sure multi-character emojis are\n",
        "    # matched first\n",
        "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
        "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
        "    return re.compile(pattern)\n",
        "\n",
        "\n",
        "def clean_line_parallel(params):\n",
        "    part, emoticons_ = params\n",
        "    return part.apply(lambda row: clean_line(row, emoticons_))\n",
        "\n",
        "\n",
        "def clean_line(line, emos=None):\n",
        "    if not line:\n",
        "        return ''\n",
        "    EMOJI = r'emj'\n",
        "    URL = r'url'\n",
        "    PUNCT = r'pnc'\n",
        "    remove = ['your comment has been removed', 'this comment or post has been removed', 'removed ', 'removed. ',\n",
        "              'your submission has been remove', 'this post has been removed', 'your post has been removed']\n",
        "    line = line.lower()\n",
        "    if any(re.match(r, line) for r in remove):\n",
        "        return ''\n",
        "    line = get_emoji_regexp().sub(EMOJI, line)\n",
        "    if emos is None:\n",
        "        emoticons_ = emoticons\n",
        "    else:\n",
        "        emoticons_ = emos\n",
        "    for emoticon in emoticons_:\n",
        "        line = line.replace(emoticon, EMOJI)\n",
        "    line = re.sub(r'\\(?http\\S+\\)?', URL, line)\n",
        "    return line\n",
        "\n",
        "\n",
        "def posify(txt):\n",
        "    \"\"\"\n",
        "    Converts txt to part of speech tags\n",
        "    \"\"\"\n",
        "    return ' '.join([pair[1] for pair in pos_tag(txt.split())])\n",
        "\n",
        "\n",
        "def posifyNew(txt):\n",
        "    \"\"\"\n",
        "    Converts txt to pairs of word & POS\n",
        "    \"\"\"\n",
        "    return ' '.join([' '.join(pos) for pos in pos_tag(txt.split())])\n",
        "\n",
        "\n",
        "def posifyNew2(txt):\n",
        "    \"\"\"\n",
        "    Appends pos text to txt\n",
        "    \"\"\"\n",
        "    return txt + ' ' + ' '.join([pos[1] for pos in pos_tag(txt.split())])\n",
        "\n",
        "\n",
        "def sentecize(txt):\n",
        "    return tokenizer.tokenize(txt)\n",
        "\n",
        "\n",
        "# sentiment analysis per sentence\n",
        "def createSentiments(ser, sia):\n",
        "    sentiments = ser.apply(lambda row: {k:v for k,v in sia.polarity_scores(row).items() if k != 'compound'})\n",
        "    return sentiments\n",
        "\n",
        "\n",
        "def aggregate(df, sentences_n=SENTENCES_N):\n",
        "    df_agg = df.groupby(df.index // sentences_n).agg({'txt': ' '.join, 'pos': ' '.join, 'sentiment': ' '.join, 'txt_with_sentiments': ' '.join, 'gender': 'first'}).reset_index(drop=True).copy()\n",
        "    return df_agg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMOJI = r'emj'\n",
        "URL = r'url'\n",
        "MALE, FEMALE = 0, 1\n",
        "lbl_to_id = {\"male\": MALE, \"female\": FEMALE}\n",
        "id_to_lbl = {i: lbl for lbl,i in lbl_to_id.items()}"
      ],
      "metadata": {
        "id": "_jRZcgFbL2ni"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETcKorg5Bo2W",
        "outputId": "74414f3a-7f79-4abc-dc8b-897ea4ff7a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon 27 Mar 2023 01:27:40 PM UTC\n",
            "Program started\n",
            "Mon 27 Mar 2023 01:27:40 PM UTC\n"
          ]
        }
      ],
      "source": [
        "!date\n",
        "\n",
        "ts = datetime.now()\n",
        "print('Program started')\n",
        "\n",
        "PRECUT = 0.30\n",
        "CLASS_SIZE = None  # None to take min max\n",
        "SELECT_K_BEST = 100\n",
        "TRAIN_FRAC = 0.70\n",
        "MIN_SENT_LEN = 5  # in tokens  # TODO: Do some trials\n",
        "\n",
        "DRIVE_ROOT_DATA_DIR = Path(\"/content/gdrive/MyDrive/gender-project/\")\n",
        "DATASET_PATH = DRIVE_ROOT_DATA_DIR / \"dataset3 and 2021-11-06 19-51-29\"\n",
        "RAW_DATASET_PATH = DATASET_PATH / \"raw\"\n",
        "CLEAN_DATASET_PATH = DATASET_PATH / \"clean\"\n",
        "EXTRA_DIR = DRIVE_ROOT_DATA_DIR / \"extra\"\n",
        "EMOTICONS_LST_FILE = \"emoticons.txt\"\n",
        "FUNCTION_WORDS_LST_FILE = \"fw.txt\"\n",
        "\n",
        "# read dataset\n",
        "if not os.path.exists(CLEAN_DATASET_PATH / \"train.parquet\"):\n",
        "    data = pd.read_csv(RAW_DATASET_PATH / \"data.csv\")\n",
        "    if 0 < PRECUT < 1:\n",
        "        data = data.sample(frac=PRECUT, random_state=SEED)\n",
        "\n",
        "    data = data.drop(data[(data.gender != 'male') & (data.gender != 'female')].index).reset_index(drop=True)\n",
        "\n",
        "    # Clean\n",
        "    clean_ts = datetime.now()\n",
        "    print('Cleaning...', end=' ')\n",
        "    with open(EXTRA_DIR / EMOTICONS_LST_FILE) as f:\n",
        "        emoticons = [emoticon.lower() for emoticon in list(set(f.read().split()))]\n",
        "    if MIN_SENT_LEN > 1:\n",
        "        # TODO: Ditch short before or after exploding?!\n",
        "        data[data.txt.str.split().apply(len) < MIN_SENT_LEN] = ''\n",
        "        # data = data[data.txt.str.split().apply(len) >= MIN_SENT_LEN].reset_index(drop=True)\n",
        "\n",
        "    # PARALLEL BEGIN\n",
        "    pools = cpu_count()\n",
        "    with Pool(pools) as pool:\n",
        "        groups = [(part, emoticons) for part in np.array_split(data['txt'], pools)]\n",
        "        data['txt'] = pd.concat(pool.map(clean_line_parallel, groups), axis=0)\n",
        "    # PARALLEL END\n",
        "\n",
        "    data = data.replace('', np.nan).dropna().reset_index(drop=True)\n",
        "    print(datetime.now() - clean_ts)\n",
        "\n",
        "    # split to genders\n",
        "    print('Splitting to genders...')\n",
        "    male = data.loc[data['gender'] == 'male', ['txt']]\n",
        "    female = data.loc[data['gender'] == 'female', ['txt']]\n",
        "\n",
        "    # split to sentences\n",
        "    print('Splitting to sentences...')\n",
        "    tokenizer = nltk_data.load('tokenizers/punkt/english.pickle')\n",
        "    male = male.apply(lambda row: sentecize(row['txt']), axis=1).explode('txt').apply(lambda row: row.strip()).replace('', np.nan).dropna().to_frame('txt').copy().reset_index(drop=True)\n",
        "    female = female.apply(lambda row: sentecize(row['txt']), axis=1).explode('txt').apply(lambda row: row.strip()).replace('', np.nan).dropna().to_frame('txt').copy().reset_index(drop=True)\n",
        "\n",
        "    print('Sentiment analysis...', end=' ')\n",
        "    sia_ts = datetime.now()\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    sentiments = createSentiments(male['txt'], sia)\n",
        "    male['sentiment'] = male.apply(lambda row: max(sentiments[row.name], key=sentiments[row.name].get), axis=1)\n",
        "    male['txt_with_sentiments'] = male.apply(lambda row: row['txt'] + ' ' + max(sentiments[row.name], key=sentiments[row.name].get), axis=1)\n",
        "    sentiments = createSentiments(female['txt'], sia)\n",
        "    female['sentiment'] = female.apply(lambda row: max(sentiments[row.name], key=sentiments[row.name].get), axis=1)\n",
        "    female['txt_with_sentiments'] = female.apply(lambda row: row['txt'] + ' ' + max(sentiments[row.name], key=sentiments[row.name].get), axis=1)\n",
        "    print(datetime.now() - sia_ts)\n",
        "    print(f\"Example: {male['txt_with_sentiments'][0]}\")\n",
        "\n",
        "    # posify\n",
        "    print('Posifying...', end=' ')\n",
        "    ts_pos = datetime.now()\n",
        "    with Pool(cpu_count()) as pool:\n",
        "        # only pos\n",
        "        # male['pos'] = pool.map(posify, male['txt'])\n",
        "        # female['pos'] = pool.map(posify, female['txt'])\n",
        "        # txt and pos together\n",
        "        male['pos'] = pool.map(posifyNew, male['txt'])\n",
        "        female['pos'] = pool.map(posifyNew, female['txt'])\n",
        "    print(datetime.now() - ts_pos)\n",
        "\n",
        "    # add labels\n",
        "    print('Adding labels...')\n",
        "    male['gender'] = [id_to_lbl[MALE]] * len(male)\n",
        "    female['gender'] = [id_to_lbl[FEMALE]] * len(female)\n",
        "\n",
        "    # sample randomly and aggregate\n",
        "    select_n = CLASS_SIZE if CLASS_SIZE and CLASS_SIZE <= min(len(male), len(female)) else min(len(male), len(female))\n",
        "    print(f'Class size: {select_n}')\n",
        "    print('Shuffling and aggregating...')\n",
        "    male = male.sample(n=select_n, random_state=SEED).reset_index(drop=True)\n",
        "    female = female.sample(n=select_n, random_state=SEED).reset_index(drop=True)\n",
        "    male = aggregate(male)\n",
        "    female = aggregate(female)\n",
        "    print(f'Class size (M,F): {len(male)}, {len(female)}')\n",
        "\n",
        "    # merge and shuffle\n",
        "    print('Merging and shuffling...')\n",
        "    data = pd.concat([male, female]).reset_index(drop=True).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "    # split to train / test\n",
        "    print('Splitting to train / test...')\n",
        "    test = data.iloc[int(len(data) * TRAIN_FRAC):].reset_index(drop=True)\n",
        "    train = data.iloc[:int(len(data) * TRAIN_FRAC)]\n",
        "    print(f'Train size: {len(train)}')\n",
        "    print(f'Test size: {len(test)}')\n",
        "    display(train.head(1))\n",
        "    display(pd.concat((train[LABEL].value_counts().rename(\"train\"), test[LABEL].value_counts().rename(\"test\")), axis=1))\n",
        "\n",
        "    if not os.path.exists(CLEAN_DATASET_PATH):\n",
        "        os.makedirs(CLEAN_DATASET_PATH)\n",
        "\n",
        "    train.to_json(CLEAN_DATASET_PATH / \"train.json\")\n",
        "    train.to_parquet(CLEAN_DATASET_PATH / \"train.parquet\")\n",
        "\n",
        "    test.to_json(CLEAN_DATASET_PATH / \"validation.json\")\n",
        "    test.to_parquet(CLEAN_DATASET_PATH / \"validation.parquet\")\n",
        "\n",
        "!date"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    del train\n",
        "    del test\n",
        "except NameError:\n",
        "    pass"
      ],
      "metadata": {
        "id": "0soDNu3nKyR3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp = pd.read_parquet(CLEAN_DATASET_PATH / \"train.parquet\")\n",
        "columns = temp.columns.tolist()\n",
        "display(temp.head(1))\n",
        "del temp\n",
        "dataset = load_dataset(\"parquet\",\n",
        "                    data_files={\"train\": str(CLEAN_DATASET_PATH / \"train.parquet\"),\n",
        "                                \"validation\": str(CLEAN_DATASET_PATH / \"validation.parquet\")})\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332,
          "referenced_widgets": [
            "573d26db6c774c73b42d6ea5a0b76b6e",
            "eda3f1d529d148bda36d49163809929c",
            "8ef1cd61a2664b218065785c1d3f1ff1",
            "bb0b3e8289b646fa85556eeb9271e6ee",
            "6430d288d6fb4284afdd7908e19231bf",
            "8406496c6f8442ee87c03ffde4110593",
            "335e0dec7a404300a12de9af0970ab94",
            "0222fed80492495c8db7d84a75311b73",
            "c63e1e8e3ec44eb6a2fc8e0706b00bfc",
            "50248f9d04524c4b88b4474dea9afd30",
            "9b664a8d8f3649658363eb2006285401"
          ]
        },
        "id": "AqDc3hNqK4ql",
        "outputId": "aa48e155-d24a-4949-984b-454bce3e1c72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                 txt  \\\n",
              "0  people really don't understand this. the only ...   \n",
              "\n",
              "                                                 pos        sentiment  \\\n",
              "0  people NNS really RB don't JJ understand NN th...  neu neu neu neu   \n",
              "\n",
              "                                 txt_with_sentiments gender  \n",
              "0  people really don't understand this. neu the o...   male  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7aae79f-1141-403e-a54e-27918a3712f5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>txt</th>\n",
              "      <th>pos</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>txt_with_sentiments</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>people really don't understand this. the only ...</td>\n",
              "      <td>people NNS really RB don't JJ understand NN th...</td>\n",
              "      <td>neu neu neu neu</td>\n",
              "      <td>people really don't understand this. neu the o...</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7aae79f-1141-403e-a54e-27918a3712f5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7aae79f-1141-403e-a54e-27918a3712f5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7aae79f-1141-403e-a54e-27918a3712f5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset parquet (/root/.cache/huggingface/datasets/parquet/default-eb966fd658d89a22/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "573d26db6c774c73b42d6ea5a0b76b6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['txt', 'pos', 'sentiment', 'txt_with_sentiments', 'gender'],\n",
              "        num_rows: 15910\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['txt', 'pos', 'sentiment', 'txt_with_sentiments', 'gender'],\n",
              "        num_rows: 6820\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(pd.Series(dataset[\"train\"][LABEL]).rename(\"train\").value_counts(dropna=False))\n",
        "print(\"\")\n",
        "display(pd.Series(dataset[\"validation\"][LABEL]).rename(\"test\").value_counts(dropna=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "5JW-Ln8fLgvT",
        "outputId": "a9948f67-010d-4440-8f21-a35b79bf4713"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "male      7970\n",
              "female    7940\n",
              "Name: train, dtype: int64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "female    3425\n",
              "male      3395\n",
              "Name: test, dtype: int64"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import cpu_count\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 4\n",
        "model_path = \"bert-base-uncased\"\n",
        "# model_path = \"Fan-s/reddit-tc-bert\"\n",
        "num_labels = len(lbl_to_id)\n",
        "num_workers = cpu_count()\n",
        "print(f\"{num_workers = }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdotBsv_L7Ny",
        "outputId": "ebf0ccbf-b6a3-4319-9a45-5055d2701503"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_workers = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use GPU if available\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Running on {device}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "804LoMEcMDmX",
        "outputId": "2cda99ba-b3af-449a-84df-6a9f62f317d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "possible_sent = ['neu', 'pos', 'neg']\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    encoded = tokenizer(examples[\"txt\"],\n",
        "                        padding=\"max_length\",\n",
        "                        truncation=True,\n",
        "                        return_tensors=\"pt\")\n",
        "    sentiments = np.zeros((len(examples['sentiment']), len(possible_sent)))\n",
        "    for i, sentiment_s in enumerate(examples['sentiment']):\n",
        "        cnt = Counter(sentiment_s.split())\n",
        "        for j, k in enumerate(possible_sent):\n",
        "            sentiments[i, j] = cnt.get(k, 0) / SENTENCES_N\n",
        "            \n",
        "    encoded[\"sentiment\"] = sentiments\n",
        "    encoded[\"labels\"] = [lbl_to_id[ex] for ex in examples[LABEL]]\n",
        "    return encoded\n",
        "\n",
        "\n",
        "encoded_dataset = dataset.map(tokenize_function, batched=True, num_proc=num_workers, remove_columns=columns)\n",
        "\n",
        "# data_collator = DataCollatorWithPadding(\n",
        "#     tokenizer=tokenizer,\n",
        "#     padding='longest',\n",
        "#     return_tensors='pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqiHNHASM3wH",
        "outputId": "fe99e09e-7304-44d4-f069-c615dca8463c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/parquet/default-eb966fd658d89a22/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-796a5c2af7ba1693_*_of_00002.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/parquet/default-eb966fd658d89a22/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-90dbecc2623ff94d_*_of_00002.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
        "#                                                            label2id=lbl_to_id,\n",
        "#                                                            id2label=id_to_lbl,\n",
        "#                                                            num_labels=num_labels).to(device)\n",
        "\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "VJ4KqLnKNmfw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Union, Tuple\n",
        "from transformers import BertModel, BertPreTrainedModel\n",
        "from torch import cat as torch_cat\n",
        "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss, Dropout, Linear, Module\n",
        "from torch.nn.functional import leaky_relu\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput\n",
        "\n",
        "\n",
        "class ClassificationHead(Module):\n",
        "    def __init__(self, bert_hidden_size, extra_data_input_size, extra_data_hidden_size, compound_hidden_size, num_labels, dropout_p=0.5):\n",
        "        super().__init__()\n",
        "        self.ff_extra_data = Linear(extra_data_input_size, extra_data_hidden_size)\n",
        "        self.ff_compound = Linear(bert_hidden_size + extra_data_hidden_size, compound_hidden_size)\n",
        "        self.dropout = Dropout(dropout_p)\n",
        "        self.ff = Linear(compound_hidden_size, num_labels)\n",
        "    \n",
        "    def forward(self, cls_embed, extra_data, **kwargs):\n",
        "        extra_data = leaky_relu(self.ff_extra_data(extra_data))\n",
        "\n",
        "        output = torch_cat((cls_embed, extra_data), dim=-1)\n",
        "        output = leaky_relu(self.ff_compound(output))\n",
        "        output = self.dropout(output)\n",
        "        output = self.ff(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class MyBert(BertPreTrainedModel):\n",
        "    # https://github.com/huggingface/transformers/blob/cae78c46d658a8e496a815c2ee49b9b178fb9c9a/src/transformers/models/bert/modeling_bert.py#L1517\n",
        "    def __init__(self, config, extra_dims_size):\n",
        "        super(MyBert, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.config = config\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        classifier_dropout = (\n",
        "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
        "        )\n",
        "        self.dropout = Dropout(classifier_dropout)\n",
        "\n",
        "        # self.classifier = Linear(config.hidden_size + extra_dims_size, config.num_labels)\n",
        "        self.classifier = ClassificationHead(bert_hidden_size=config.hidden_size,\n",
        "                                             extra_data_input_size=extra_dims_size,\n",
        "                                             extra_data_hidden_size=128,\n",
        "                                             compound_hidden_size=1024,\n",
        "                                             num_labels=config.num_labels)\n",
        "\n",
        "        # Initialize weights and apply final processing\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids: Optional[torch.Tensor] = None,\n",
        "        attention_mask: Optional[torch.Tensor] = None,\n",
        "        sentiment: Optional[torch.FloatTensor] = None,\n",
        "        token_type_ids: Optional[torch.Tensor] = None,\n",
        "        position_ids: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        inputs_embeds: Optional[torch.Tensor] = None,\n",
        "        labels: Optional[torch.Tensor] = None,\n",
        "        output_attentions: Optional[bool] = None,\n",
        "        output_hidden_states: Optional[bool] = None,\n",
        "        return_dict: Optional[bool] = None,\n",
        "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
        "        r\"\"\"\n",
        "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
        "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
        "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
        "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
        "        \"\"\"\n",
        "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
        "\n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        )\n",
        "\n",
        "        cls_embed = outputs[0][:, 0, :]\n",
        "\n",
        "        logits = self.classifier(cls_embed, sentiment)\n",
        "\n",
        "        loss = None\n",
        "        if labels is not None:\n",
        "            if self.config.problem_type is None:\n",
        "                if self.num_labels == 1:\n",
        "                    self.config.problem_type = \"regression\"\n",
        "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
        "                    self.config.problem_type = \"single_label_classification\"\n",
        "                else:\n",
        "                    self.config.problem_type = \"multi_label_classification\"\n",
        "\n",
        "            if self.config.problem_type == \"regression\":\n",
        "                loss_fct = MSELoss()\n",
        "                if self.num_labels == 1:\n",
        "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
        "                else:\n",
        "                    loss = loss_fct(logits, labels)\n",
        "            elif self.config.problem_type == \"single_label_classification\":\n",
        "                loss_fct = CrossEntropyLoss()\n",
        "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "            elif self.config.problem_type == \"multi_label_classification\":\n",
        "                loss_fct = BCEWithLogitsLoss()\n",
        "                loss = loss_fct(logits, labels)\n",
        "        if not return_dict:\n",
        "            output = (logits,) + outputs[2:]\n",
        "            return ((loss,) + output) if loss is not None else output\n",
        "\n",
        "        return SequenceClassifierOutput(\n",
        "            loss=loss,\n",
        "            logits=logits,\n",
        "            hidden_states=outputs.hidden_states,\n",
        "            attentions=outputs.attentions,\n",
        "        )\n",
        "\n",
        "model = MyBert.from_pretrained(model_path,\n",
        "                               extra_dims_size=len(possible_sent),\n",
        "                               label2id=lbl_to_id,\n",
        "                               id2label=id_to_lbl,\n",
        "                               num_labels=num_labels).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "itHMnlR7K4A9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37989b61-0013-44a3-b513-3c0e6500614b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing MyBert: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing MyBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MyBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of MyBert were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.ff_compound.bias', 'classifier.ff_extra_data.bias', 'classifier.ff_extra_data.weight', 'classifier.ff.weight', 'classifier.ff_compound.weight', 'classifier.ff.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyBert(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): ClassificationHead(\n",
            "    (ff_extra_data): Linear(in_features=3, out_features=128, bias=True)\n",
            "    (ff_compound): Linear(in_features=896, out_features=1024, bias=True)\n",
            "    (dropout): Dropout(p=0.5, inplace=False)\n",
            "    (ff): Linear(in_features=1024, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "gradient_accumulation_steps = 4\n",
        "iters_per_epoch = len(dataset[\"train\"][LABEL]) // (BATCH_SIZE * gradient_accumulation_steps)\n",
        "training_args = TrainingArguments(evaluation_strategy='epoch',\n",
        "                                  optim='adamw_torch',\n",
        "                                  logging_steps=iters_per_epoch,\n",
        "                                  per_device_train_batch_size=BATCH_SIZE,\n",
        "                                  per_device_eval_batch_size=BATCH_SIZE,\n",
        "                                  num_train_epochs=EPOCHS,\n",
        "                                  save_total_limit=1,\n",
        "                                  save_strategy='epoch',\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  fp16=device == 'cuda',\n",
        "                                  gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "                                  output_dir='model_checkpoints')"
      ],
      "metadata": {
        "id": "Q5YBEJCPNtnG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    preds, labels = eval_pred\n",
        "    preds = np.argmax(preds, axis=-1)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=0)\n",
        "    p_per_lbl, r_per_lbl, f1_per_lbl, _ = precision_recall_fscore_support(\n",
        "        y_true=labels, y_pred=preds, labels=range(num_labels), average=None, zero_division=0\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    d = {\"accuracy\": acc, \"precision\": p, \"recall\": r, \"f1\": f1}\n",
        "\n",
        "    for id_ in range(num_labels):\n",
        "        cls = id_to_lbl[id_]\n",
        "        d[f\"{cls} precision\"] = p_per_lbl[id_]\n",
        "        d[f\"{cls} recall\"] = r_per_lbl[id_]\n",
        "        d[f\"{cls} f1\"] = f1_per_lbl[id_]\n",
        "\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "4btvW5wBOA3f"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset[\"train\"],\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    # data_collator=data_collator,\n",
        ")"
      ],
      "metadata": {
        "id": "v-B4h1JoOJMV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "MP90Jw8DOLmB",
        "outputId": "89fe5e74-7401-4cda-d89f-23f93552181b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='992' max='992' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [992/992 41:39, Epoch 3/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Male precision</th>\n",
              "      <th>Male recall</th>\n",
              "      <th>Male f1</th>\n",
              "      <th>Female precision</th>\n",
              "      <th>Female recall</th>\n",
              "      <th>Female f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.566200</td>\n",
              "      <td>0.496260</td>\n",
              "      <td>0.761584</td>\n",
              "      <td>0.766772</td>\n",
              "      <td>0.761584</td>\n",
              "      <td>0.760311</td>\n",
              "      <td>0.803639</td>\n",
              "      <td>0.689543</td>\n",
              "      <td>0.742232</td>\n",
              "      <td>0.730228</td>\n",
              "      <td>0.832993</td>\n",
              "      <td>0.778232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.362500</td>\n",
              "      <td>0.530484</td>\n",
              "      <td>0.764223</td>\n",
              "      <td>0.768378</td>\n",
              "      <td>0.764223</td>\n",
              "      <td>0.763398</td>\n",
              "      <td>0.734330</td>\n",
              "      <td>0.824742</td>\n",
              "      <td>0.776915</td>\n",
              "      <td>0.802128</td>\n",
              "      <td>0.704234</td>\n",
              "      <td>0.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.171100</td>\n",
              "      <td>0.653704</td>\n",
              "      <td>0.766569</td>\n",
              "      <td>0.766572</td>\n",
              "      <td>0.766569</td>\n",
              "      <td>0.766570</td>\n",
              "      <td>0.765069</td>\n",
              "      <td>0.766421</td>\n",
              "      <td>0.765745</td>\n",
              "      <td>0.768061</td>\n",
              "      <td>0.766715</td>\n",
              "      <td>0.767387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.071800</td>\n",
              "      <td>0.939951</td>\n",
              "      <td>0.762463</td>\n",
              "      <td>0.767988</td>\n",
              "      <td>0.762463</td>\n",
              "      <td>0.761123</td>\n",
              "      <td>0.806140</td>\n",
              "      <td>0.688365</td>\n",
              "      <td>0.742612</td>\n",
              "      <td>0.730171</td>\n",
              "      <td>0.835912</td>\n",
              "      <td>0.779472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_path = DRIVE_ROOT_DATA_DIR / \"pytorch_bert_with_sentiment\"  # 2% accuracy gain!\n",
        "best_model_zipped_path = f\"{best_model_path}.zip\"\n",
        "if os.path.exists(best_model_path):\n",
        "    !rm -r {best_model_path}\n",
        "if os.path.exists(best_model_zipped_path):\n",
        "    !rm {best_model_zipped_path}\n",
        "\n",
        "trainer.save_model(best_model_path)\n",
        "!zip -j -r {best_model_zipped_path} {best_model_path}\n",
        "!rm -r {best_model_path}"
      ],
      "metadata": {
        "id": "7uRuCYmvQFwD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fec9118-31dd-493f-954b-dc3d71eee8f4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: config.json (deflated 50%)\n",
            "  adding: pytorch_model.bin (deflated 7%)\n",
            "  adding: training_args.bin (deflated 49%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "573d26db6c774c73b42d6ea5a0b76b6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eda3f1d529d148bda36d49163809929c",
              "IPY_MODEL_8ef1cd61a2664b218065785c1d3f1ff1",
              "IPY_MODEL_bb0b3e8289b646fa85556eeb9271e6ee"
            ],
            "layout": "IPY_MODEL_6430d288d6fb4284afdd7908e19231bf"
          }
        },
        "eda3f1d529d148bda36d49163809929c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8406496c6f8442ee87c03ffde4110593",
            "placeholder": "",
            "style": "IPY_MODEL_335e0dec7a404300a12de9af0970ab94",
            "value": "100%"
          }
        },
        "8ef1cd61a2664b218065785c1d3f1ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0222fed80492495c8db7d84a75311b73",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c63e1e8e3ec44eb6a2fc8e0706b00bfc",
            "value": 2
          }
        },
        "bb0b3e8289b646fa85556eeb9271e6ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50248f9d04524c4b88b4474dea9afd30",
            "placeholder": "",
            "style": "IPY_MODEL_9b664a8d8f3649658363eb2006285401",
            "value": " 2/2 [00:00&lt;00:00, 65.60it/s]"
          }
        },
        "6430d288d6fb4284afdd7908e19231bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8406496c6f8442ee87c03ffde4110593": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "335e0dec7a404300a12de9af0970ab94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0222fed80492495c8db7d84a75311b73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63e1e8e3ec44eb6a2fc8e0706b00bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50248f9d04524c4b88b4474dea9afd30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b664a8d8f3649658363eb2006285401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}